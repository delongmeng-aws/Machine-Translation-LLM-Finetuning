{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81fe1856-c907-405f-b6d4-afadb3e0b721",
   "metadata": {},
   "source": [
    "# Machine translation with pretrained t5 model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdecd67-d950-4e88-ad8a-5e67503813d7",
   "metadata": {},
   "source": [
    "This notebook provides an example solution for a Machine Translation. This solution uses a large language model, the [google/flan-t5-xl model](https://huggingface.co/google/flan-t5-xl) (3B parameters) from the Hugging Face platform, to translate text from English to multiple target languages. \n",
    "\n",
    "Compute resource: Amazon SageMaker ml.g4dn.xlarge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c9e697-fb9c-4fe3-95cc-e6b66d2e6bb6",
   "metadata": {},
   "source": [
    "First, install and import libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebb0896f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip3 install -q ipykernel==6.22.0\n",
    "!pip3 install -q torch==2.0.1\n",
    "!pip3 install -q transformers==4.28.1\n",
    "!pip3 install -q bitsandbytes==0.39.0\n",
    "!pip3 install -q peft==0.3.0\n",
    "!pip3 install -q pytest==7.3.2\n",
    "!pip3 install -q datasets==2.10.0\n",
    "!pip3 install -q sentencepiece\n",
    "!pip3 install -q accelerate\n",
    "!pip3 install -q nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2579fc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import pipeline, AutoTokenizer, T5Tokenizer, T5ForConditionalGeneration\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "import tqdm\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "import os\n",
    "import numpy as np\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "\n",
    "BLEU = 'bleu'\n",
    "\n",
    "language_mapping = {\"es\":\"Spanish\", \"de\":\"German\", \"fr\": \"French\", \"it\":\"Italian\", \"pt\":\"Portuguese\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d63ffd3a-1943-4632-93b2-944fb22f7b1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "829104e4-cf49-4547-b6c5-3f3fff6c5529",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed = 100\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9dd6ed",
   "metadata": {},
   "source": [
    "## Load Pretrained Model from Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "878efc10-0fef-4c81-8d93-180c422dd4a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7356bb68a6e4fa6a2058a40d45258ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"google/flan-t5-xl\" # Hugging Face Model Id\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_id)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_id, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b320856-2b5a-4d47-a042-a52fb6ddfa81",
   "metadata": {},
   "source": [
    "## Load dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f17c26a",
   "metadata": {},
   "source": [
    "The dataset has the following columns: \n",
    "- `ID`\n",
    "- `input_to_translate`: the source sentence in English\n",
    "- `label`: the translation reference in the target language\n",
    "- `gender`: f(emale) or m(ale)\n",
    "- `language_pair`: `<source>_<target>`, such as en_fr for English to French"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e182536b-e94a-4d6d-9105-bd51377cbda1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>input_to_translate</th>\n",
       "      <th>label</th>\n",
       "      <th>gender</th>\n",
       "      <th>language_pair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>She started training for the biathlon in 2003.</td>\n",
       "      <td>Comenzó a entrenar para el biatlón en 2003.</td>\n",
       "      <td>f</td>\n",
       "      <td>en_es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>He joined Philippine Airlines as a trainee pil...</td>\n",
       "      <td>Er wurde Flugschüler bei Philippine Airlines u...</td>\n",
       "      <td>m</td>\n",
       "      <td>en_de</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                 input_to_translate  \\\n",
       "0   0     She started training for the biathlon in 2003.   \n",
       "1   1  He joined Philippine Airlines as a trainee pil...   \n",
       "\n",
       "                                               label gender language_pair  \n",
       "0        Comenzó a entrenar para el biatlón en 2003.      f         en_es  \n",
       "1  Er wurde Flugschüler bei Philippine Airlines u...      m         en_de  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_features = pd.read_csv(\"data/training.csv\", encoding=\"utf-8-sig\")\n",
    "training_features.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4308b5f1-29bb-42e2-9285-f980c5d19697",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_prompt(x):\n",
    "    language_mapping = {\"es\":\"Spanish\", \"de\":\"German\", \"fr\": \"French\", \"it\":\"Italian\", \"pt\":\"Portuguese\"}\n",
    "    source_text = x[\"input_to_translate\"]\n",
    "    language = x[\"language_pair\"].split('_')[1]\n",
    "    input_text = f\"Translate the following sentence from English to {language_mapping[language]}: \\\"{source_text}\\\" \"\n",
    "    return input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bee3d61-0134-41cd-bb9b-ed7d92044398",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>input_to_translate</th>\n",
       "      <th>label</th>\n",
       "      <th>gender</th>\n",
       "      <th>language_pair</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>She started training for the biathlon in 2003.</td>\n",
       "      <td>Comenzó a entrenar para el biatlón en 2003.</td>\n",
       "      <td>f</td>\n",
       "      <td>en_es</td>\n",
       "      <td>Translate the following sentence from English ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>He joined Philippine Airlines as a trainee pil...</td>\n",
       "      <td>Er wurde Flugschüler bei Philippine Airlines u...</td>\n",
       "      <td>m</td>\n",
       "      <td>en_de</td>\n",
       "      <td>Translate the following sentence from English ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                 input_to_translate  \\\n",
       "0   0     She started training for the biathlon in 2003.   \n",
       "1   1  He joined Philippine Airlines as a trainee pil...   \n",
       "\n",
       "                                               label gender language_pair  \\\n",
       "0        Comenzó a entrenar para el biatlón en 2003.      f         en_es   \n",
       "1  Er wurde Flugschüler bei Philippine Airlines u...      m         en_de   \n",
       "\n",
       "                                              prompt  \n",
       "0  Translate the following sentence from English ...  \n",
       "1  Translate the following sentence from English ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_features[\"prompt\"] = training_features.apply(generate_prompt, axis=1)\n",
    "training_features.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1815555",
   "metadata": {},
   "source": [
    "#### Check the generated prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a447ce05-19c4-4dd8-ac49-3e7ae150c6bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Translate the following sentence from English to Spanish: \"She started training for the biathlon in 2003.\" '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_features.iloc[0][\"prompt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "193e11ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Translate the following sentence from English to German: \"He joined Philippine Airlines as a trainee pilot, and was later pirated by Boeing.\" '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_features.iloc[1][\"prompt\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf680f0",
   "metadata": {},
   "source": [
    "#### Load and generate prompt for test set\n",
    "\n",
    "The test set is smilar with the training set, except that it is lacking the \"label\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85b80913-70c2-48b9-b97e-f2b165255e88",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ID', 'input_to_translate', 'gender', 'language_pair']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features = pd.read_csv(\"data/test_features.csv\", encoding=\"utf-8-sig\")\n",
    "list(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b87e1759-1450-4c71-a22a-035dcb594ce8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ID', 'input_to_translate', 'gender', 'language_pair', 'prompt']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features[\"prompt\"] = test_features.apply(generate_prompt, axis=1)\n",
    "list(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669d599c-b0d2-4e5f-a2eb-0b04c542959e",
   "metadata": {},
   "source": [
    "### Try to use the model to translate input text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68ee5d7e-88a0-431e-8e26-7ce3e12da223",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Er kam als Flugschüler zu Philippine Airlines und wurde später von Boeing raubkopiert.\"\n"
     ]
    }
   ],
   "source": [
    "input_text = training_features.iloc[1][\"prompt\"]\n",
    "input_ids = tokenizer(input_text, padding=True, truncation=True, max_length=512, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(input_ids, max_length=1024)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3cda03d1-c49a-4e23-85dd-986a857187e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Translate the following sentence from English to German: \"He joined Philippine Airlines as a trainee pilot, and was later pirated by Boeing.\" '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae72a99e-b78f-426f-a7b6-05ff84152f63",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Er wurde Flugsch√ºler bei Philippine Airlines und wurde sp√§ter von Boeing abgeworben.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reference translation\n",
    "training_features.iloc[1][\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191bcb3e-e0dc-4ada-9bd1-a0d58cef7d80",
   "metadata": {},
   "source": [
    "Translate a few sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f77e021-01e7-471b-8fd3-9e8800fbcfe6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 7.15 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [10:33<00:00, 63.32s/it]\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "language_mapping = {\"es\":\"Spanish\", \"de\":\"German\", \"fr\": \"French\", \"it\":\"Italian\", \"pt\":\"Portuguese\"}\n",
    "predicted_labels = []\n",
    "prediction = pd.DataFrame({\"ID\": pd.Series(dtype=\"int\"),\n",
    "                   \"predicted_label\": pd.Series(dtype=\"str\")})\n",
    "\n",
    "sample_size = 10\n",
    "\n",
    "for row in tqdm.tqdm(range(sample_size)):\n",
    "    sentence_id = training_features.iloc[row][\"ID\"]\n",
    "    input_text = training_features.iloc[row][\"prompt\"]\n",
    "    input_ids = tokenizer(input_text, padding=True, truncation=True, max_length=512, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "\n",
    "    outputs = model.generate(input_ids, max_length=1024)\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    predicted_labels.append(generated_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c342a4-f293-42ad-b38c-bb478ec91ea4",
   "metadata": {},
   "source": [
    "## Use Hugging Face pipeline instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea94f3ec-6399-4f59-8223-c8b6712eb87a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/pipelines/__init__.py:958: UserWarning: \"translation\" task was used, instead of \"translation_XX_to_YY\", defaulting to \"translation_en_to_de\"\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"translation\", model = model, tokenizer = tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fae07a-3d5d-468a-9ded-59dc351ccd6a",
   "metadata": {},
   "source": [
    "### Translate one sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d091125-bdc1-4731-b60e-e65013c1104c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/generation/utils.py:1219: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'translation_text': '\"Er kam als Flugschüler zu Philippine Airlines und wurde später von Boeing raubkopiert.\"'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe('Translate the following sentence from English to German: \"He joined Philippine Airlines as a trainee pilot, and was later pirated by Boeing.\" ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b721c5e6-c3aa-466b-8d64-b94121f3984e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Translate a few sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23e13a78-610c-4eb5-b0e5-d8183ceb0353",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/pipelines/base.py:1070: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "100%|██████████| 10/10 [00:29<00:00,  2.91s/it]\n"
     ]
    }
   ],
   "source": [
    "language_mapping = {\"es\":\"Spanish\", \"de\":\"German\", \"fr\": \"French\", \"it\":\"Italian\", \"pt\":\"Portuguese\"}\n",
    "predicted_labels = []\n",
    "prediction = pd.DataFrame({\"ID\": pd.Series(dtype=\"int\"),\n",
    "                   \"predicted_label\": pd.Series(dtype=\"str\")})\n",
    "\n",
    "sample_size = 10\n",
    "\n",
    "for row in tqdm.tqdm(range(sample_size)):\n",
    "    sentence_id = training_features.iloc[row][\"ID\"]\n",
    "    input_text = training_features.iloc[row][\"prompt\"]\n",
    "\n",
    "    generated_text = pipe(input_text)[0]['translation_text']\n",
    "    predicted_labels.append(generated_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8ccf04",
   "metadata": {},
   "source": [
    "**Overall time is much faster than not using Pipeline!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "743480bb-669c-40ef-b977-919209467217",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction[\"ID\"] = training_features.iloc[0:sample_size][\"ID\"]\n",
    "prediction[\"predicted_label\"] = predicted_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab532cb0-cda0-472a-aca7-65141fdcce12",
   "metadata": {},
   "source": [
    "### Calculate Bleu score on training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e25f1fa3-369d-4975-9d70-24e6f52daf5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bleu_func(x, y):\n",
    "    chencherry = SmoothingFunction()\n",
    "    x_split = [x_entry.strip().split() for x_entry in x]\n",
    "    y_split = y.strip().split()\n",
    "    return sentence_bleu(x_split, y_split, smoothing_function=chencherry.method3)\n",
    "\n",
    "def bleu_custom(y_true, y_pred, groups):\n",
    "    joined = pd.concat([y_true, y_pred, groups], axis=1)\n",
    "    joined[BLEU] = joined.apply(lambda x: bleu_func([x[y_true.name]], x[y_pred.name]), axis=1)\n",
    "    values = [joined[joined[groups.name] == unique][BLEU].mean() for unique in unique_list]\n",
    "    print(f\"Overall mean: {joined[BLEU].mean()}\")\n",
    "    print(f\"Different genders: {values}\")\n",
    "    print(f\"Final score: {joined[BLEU].mean() - np.fabs(values[0] - values[1])/2}\")\n",
    "    return joined[BLEU].mean() - np.fabs(values[0] - values[1])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b022d3c9-c649-4685-b219-3f22e66b9f1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall mean: 0.2131333021255633\n",
      "Different genders: [0.22161764199499698, 0.20040679232141279]\n",
      "Final score: 0.2025278772887712\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2025278772887712"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_custom(\n",
    "    training_features.iloc[0:sample_size][\"label\"], \n",
    "    prediction[\"predicted_label\"], \n",
    "    training_features.iloc[0:sample_size][\"gender\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f57e1a1",
   "metadata": {},
   "source": [
    "Can see that in this dataset, the gender difference is not too bad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b84c3ff-15c3-4923-a620-4aa7683565ab",
   "metadata": {},
   "source": [
    "## Use Hugging Face Dataset \n",
    "\n",
    "\n",
    "https://huggingface.co/docs/transformers/main_classes/pipelines#transformers.pipeline\n",
    "\n",
    "https://huggingface.co/docs/transformers/pipeline_tutorial\n",
    "\n",
    "https://github.com/huggingface/transformers/issues/22387"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d65540c5-d3b1-482b-bbb3-163917b15179",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['ID', 'input_to_translate', 'label', 'gender', 'language_pair', 'prompt'],\n",
       "    num_rows: 10\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_size = 10\n",
    "train_ds_raw = datasets.Dataset.from_pandas(training_features.head(sample_size), split=\"train\")\n",
    "train_ds_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8327bf-04d5-4343-aef0-97d1f1078942",
   "metadata": {},
   "source": [
    "### Streaming and batching using pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fc22138-4ca1-42ea-ab51-68c4876e758e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/generation/utils.py:1219: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n",
      " 10%|█         | 1/10 [00:05<00:50,  5.65s/it]\n",
      " 30%|███       | 3/10 [00:08<00:17,  2.49s/it]\n",
      " 50%|█████     | 5/10 [00:15<00:15,  3.10s/it]\n",
      " 70%|███████   | 7/10 [00:18<00:07,  2.39s/it]\n",
      "100%|██████████| 10/10 [00:27<00:00,  2.78s/it]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_labels = []\n",
    "prediction = pd.DataFrame({\"ID\": pd.Series(dtype=\"int\"),\n",
    "                   \"predicted_label\": pd.Series(dtype=\"str\")})\n",
    "batch_size = 2\n",
    "# default batch size is 1, if not specified\n",
    "# with higher batch size, it's easier to trigger out of memory error\n",
    "\n",
    "for out in tqdm.tqdm(pipe(KeyDataset(train_ds_raw, \"prompt\"), batch_size=batch_size),total=len(train_ds_raw)):\n",
    "# for out in pipe(KeyDataset(train_ds_raw, \"prompt\")):\n",
    "# for out in tqdm.tqdm(pipe(KeyDataset(train_ds_raw, \"prompt\"))):\n",
    "\n",
    "    #print(out)\n",
    "    generated_text = out[0]['translation_text']\n",
    "    predicted_labels.append(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0b3761",
   "metadata": {},
   "source": [
    "**Overall time is similar to not using Dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4052a78b-74c7-4540-97f9-ecadcbfbf6e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction[\"ID\"] = training_features.iloc[0:sample_size][\"ID\"]\n",
    "prediction[\"predicted_label\"] = predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69808986-ff20-4452-84f1-6ceb13b03e59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall mean: 0.2131333021255633\n",
      "Different genders: [0.22161764199499698, 0.20040679232141279]\n",
      "Final score: 0.2025278772887712\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2025278772887712"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_custom(\n",
    "    training_features.iloc[0:sample_size][\"label\"], \n",
    "    prediction[\"predicted_label\"], \n",
    "    training_features.iloc[0:sample_size][\"gender\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bcc413-8b09-4500-bb50-1098727b7512",
   "metadata": {},
   "source": [
    "## Translation on test dataset with pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7880e666-848c-4824-b2c1-80c6084a2f6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['ID', 'input_to_translate', 'gender', 'language_pair', 'prompt'],\n",
       "    num_rows: 3000\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds_raw = datasets.Dataset.from_pandas(test_features, split=\"test\")\n",
    "test_ds_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46c67e5e-2440-420b-97ce-66a85d398211",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3000 [00:00<?, ?it/s]/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/generation/utils.py:1219: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n",
      "100%|██████████| 3000/3000 [2:20:48<00:00,  2.82s/it]  \n"
     ]
    }
   ],
   "source": [
    "predicted_labels = []\n",
    "test_prediction = pd.DataFrame({\"ID\": pd.Series(dtype=\"int\"), \"label\": pd.Series(dtype=\"str\")})\n",
    "batch_size = 1\n",
    "# default batch size is 1, if not specified\n",
    "# with higher batch size, it's easier to trigger out of memory error\n",
    "\n",
    "for out in tqdm.tqdm(pipe(KeyDataset(test_ds_raw, \"prompt\"), batch_size=batch_size),total=len(test_ds_raw)):\n",
    "    generated_text = out[0]['translation_text']\n",
    "    predicted_labels.append(generated_text)\n",
    "\n",
    "test_prediction[\"ID\"] = test_features[\"ID\"]\n",
    "test_prediction[\"label\"] = predicted_labels\n",
    "test_prediction.to_csv(\"t5_xl_pretrain-10102023.csv\", index = False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c67bea-16bd-4d7f-b846-38d718fbb360",
   "metadata": {},
   "source": [
    "when batch size = 2, got OOM error at 55%|█████▍    | 1646/3000\n",
    "\n",
    "when batch size = 1, it went well: 100%|██████████| 3000/3000 [2:20:48<00:00,  2.82s/it] \n",
    "\n",
    "final score: 0.167153\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca1b526-a609-482a-aee5-4e5a83d665db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv ml-basic",
   "language": "python",
   "name": "ml-basic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
